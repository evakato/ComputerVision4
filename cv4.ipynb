{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evakato/ComputerVision4/blob/main/cv4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = (\n",
        "    #Nvidia GPU\n",
        "    \"cuda\" \n",
        "    if torch.cuda.is_available()\n",
        "    #Apple GPU\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    #Other\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIpBlt59Tmmv"
      },
      "source": [
        "1. Import the Fashion MNIST dataset including the data labels. This would import two sets (training set and test set). Create a third set (validation set) by splitting the training set into two (training set and validation set) for validation purposes. Decide what a good ratio of training/validation is, and motivate your choice. You should use the validation set to evaluate the different choices you make when building your CNNs. Keep in mind that the test set will only be used at the very final stage and will not be included in the validation step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xhn0qdxVSyW0",
        "outputId": "27fd0d63-e3b0-468b-d6d1-40f0ece51573"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import ToTensor\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "#NOTE: data is not normalised yet\n",
        "train_data = datasets.FashionMNIST('Data', download=True, train=True, transform=ToTensor())\n",
        "test_data = datasets.FashionMNIST('Data', download=True, train=False, transform=ToTensor())\n",
        "\n",
        "splitlength = [50000,10000] \n",
        "#NOTE: This needs to be changed to be calculated using a percentage if we are going to have variable data lenghts (due to e.g. data augmentation)\n",
        "train_data, val_data = random_split(train_data, splitlength)\n",
        "\n",
        "batch_size = 32\n",
        "train_dataloader = DataLoader(train_data, batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_data, batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 28, 28]) 5\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x20f01427810>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgHElEQVR4nO3de2zV9f3H8ddpaQ+39pRS2lKgUG6yycWIUhsULzRcNESEGG9/gDEaWHFDpi5dVHQz6YaJW1wY7o8FZhRQF4FoFhZEW9RxCQgyozaUVSmXlsvsOW2BFtrP7w9if6tcP19O+27L85F8E3rO98X3w5cvffHtOX035JxzAgCggyVYLwAAcG2igAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCih/UCfqylpUWHDx9WSkqKQqGQ9XIAAJ6cc6qrq1NOTo4SEi5+n9PpCujw4cMaMmSI9TIAAFepqqpKgwcPvujzne5LcCkpKdZLAADEweU+n7dbAS1fvlzDhg1Tz549lZ+frx07dlxRji+7AUD3cLnP5+1SQG+//baWLFmipUuX6vPPP9eECRM0ffp0HT16tD0OBwDoilw7mDRpkisqKmr9uLm52eXk5LiSkpLLZqPRqJPExsbGxtbFt2g0esnP93G/A2pqatKuXbtUWFjY+lhCQoIKCwu1devW8/ZvbGxULBZrswEAur+4F9Dx48fV3NysrKysNo9nZWWpurr6vP1LSkoUiURaN94BBwDXBvN3wRUXFysajbZuVVVV1ksCAHSAuH8fUEZGhhITE1VTU9Pm8ZqaGmVnZ5+3fzgcVjgcjvcyAACdXNzvgJKTkzVx4kRt3ry59bGWlhZt3rxZBQUF8T4cAKCLapdJCEuWLNG8efN00003adKkSfrjH/+ohoYGPfroo+1xOABAF9QuBfTAAw/o2LFjeuGFF1RdXa0bbrhBGzduPO+NCQCAa1fIOeesF/G/YrGYIpGI9TIAAFcpGo0qNTX1os+bvwsOAHBtooAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACZ6WC8AwLUrMzPTO9O3b1/vTHJysndGkoYOHeqdSUjw/3/9p59+6p2pq6vzzkhSKBTyzjjnAh3rcrgDAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIJhpEAX8dBDD3ln6uvrAx2rvLzcOzN16lTvTJDBnSdPnvTORCIR74wkpaene2dSU1O9M5WVld6Zb775xjsjMYwUAAAKCABggwICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmGEaKbinIwMWguZaWFu/M8OHDvTM33nijd6ampsY7I0mjR4/2ziQnJ3tnggwjHTZsmHfm8OHD3hlJWr16tXdm1KhR3pmMjAzvTFBBrtf2wh0QAMAEBQQAMBH3AnrxxRcVCoXabGPGjIn3YQAAXVy7vAZ0/fXX68MPP/z/g/TgpSYAQFvt0gw9evRQdnZ2e/zWAIBuol1eA9q3b59ycnI0fPhwPfLIIzpw4MBF921sbFQsFmuzAQC6v7gXUH5+vlatWqWNGzdqxYoVqqys1G233aa6uroL7l9SUqJIJNK6DRkyJN5LAgB0QnEvoJkzZ+r+++/X+PHjNX36dP3jH/9QbW2t3nnnnQvuX1xcrGg02rpVVVXFe0kAgE6o3d8dkJaWptGjR6uiouKCz4fDYYXD4fZeBgCgk2n37wOqr6/X/v37NXDgwPY+FACgC4l7AT399NMqKyvTt99+q3/961+67777lJiYqIceeijehwIAdGFx/xLcwYMH9dBDD+nEiRMaMGCAbr31Vm3btk0DBgyI96EAAF1Y3Ato7dq18f4tcY0LMiDUORfoWEFzvu6//37vTJB3iKalpXlnJOn06dPemeeee847E41GvTMd6ZZbbvHOTJs2zTsTZFjqp59+6p3pbJgFBwAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwES7/0A6oCvJzc31zjz88MPemS+++MI7U1pa6p0pLi72zkhSv379vDPz5s3zzrz22mvemSAWL14cKDds2DDvTJDBos3Nzd6ZQYMGeWck6dChQ94Z34HAVzrUlzsgAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJpmGj00tMTPTOnD17NtCx7rrrLu/MrFmzvDPr16/3znzzzTfemdmzZ3tnJOnRRx/1zjz//PPemXvuucc7s3fvXu9Mnz59vDOS1NTU5J3Ztm2bd+bjjz/2znSkK51u7Ys7IACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYYRorAQqFQhxwn6GDRIKqrq70zb775pnfm4MGD3plIJOKdiUaj3hlJWrlypXempaXFOzN58mTvzKlTp7wzaWlp3hlJevXVV70zFRUVgY51LeIOCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgImQc85ZL+J/xWKxQEMXASs9evjP9B08eLB35ttvv/XODBgwwDsjSceOHfPOBPl3+8orr3hnkpKSOuQ4kvTVV18FyvlKSPC/Fwgy/FUKNkQ4aE1Eo1GlpqZe9HnugAAAJiggAIAJ7wLasmWLZs2apZycHIVCIa1fv77N8845vfDCCxo4cKB69eqlwsJC7du3L17rBQB0E94F1NDQoAkTJmj58uUXfH7ZsmV67bXX9Prrr2v79u3q06ePpk+frtOnT1/1YgEA3Yf3q6czZ87UzJkzL/icc05//OMf9dxzz+nee++VJL3xxhvKysrS+vXr9eCDD17dagEA3UZcXwOqrKxUdXW1CgsLWx+LRCLKz8/X1q1bL5hpbGxULBZrswEAur+4FlB1dbUkKSsrq83jWVlZrc/9WElJiSKRSOs2ZMiQeC4JANBJmb8Lrri4WNFotHWrqqqyXhIAoAPEtYCys7MlSTU1NW0er6mpaX3ux8LhsFJTU9tsAIDuL64FlJeXp+zsbG3evLn1sVgspu3bt6ugoCCehwIAdHHe74Krr69XRUVF68eVlZXas2eP0tPTlZubq8WLF+vll1/WqFGjlJeXp+eff145OTmaPXt2PNcNAOjivAto586duvPOO1s/XrJkiSRp3rx5WrVqlZ599lk1NDToiSeeUG1trW699VZt3LhRPXv2jN+qAQBdHsNIEViQAYpBBB262FEWL17snZk6dap3ZuHChd6ZxsZG74ykQO9Gvdj3B17KDTfc4J157733vDNr1qzxzuDqMYwUANApUUAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMeP84BkihUMg701FDxxMTE70zzc3NgY7VUVOqk5OTvTNpaWmBjhXk7ykrK8s788knn3hnVqxY4Z0Jeh5qa2u9M7t37/bOVFdXe2eYbH11kpKSvDO+nyOcc1f0b4k7IACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACZCrqOmZF6hWCymSCRivQxcgYkTJ3pnDh065J3JyMjwzowaNco7I0nZ2dnemc8++8w7s3fvXu9MEH369AmUW7BggXcmyDlfu3atd6a0tNQ7M3jwYO+MJI0YMcI707NnT+9Mjx4dNxe6f//+3pkdO3Z47d/c3Kx9+/YpGo0qNTX1ovtxBwQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMBEx03AQ4cIMkzz5z//eaBjPfbYY96Zhx9+2DuTnJzsnQlyHiRpwIAB3pmOGiwaRENDQ6BcTk6OdyYpKck7069fP+/M/PnzvTMtLS3eGUnq1auXd+bEiRPemebmZu9M0D/T999/7505fvy41/5XujbugAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJhgGGkAiYmJ3pkgwwbvvPNO78y6deu8M5FIxDsjSdFo1DuTmZnpndm9e7d3JshQUUn66quvAuU6q6BDWYPktm3b5p1JS0vzzgRx9OjRQLn6+nrvTDgc9s4EGSwa5HOKJPXp08c7c+rUKa/9nXNXtB93QAAAExQQAMCEdwFt2bJFs2bNUk5OjkKhkNavX9/m+fnz5ysUCrXZZsyYEa/1AgC6Ce8Camho0IQJE7R8+fKL7jNjxgwdOXKkdVuzZs1VLRIA0P14vwlh5syZmjlz5iX3CYfDgV/8BABcG9rlNaDS0lJlZmbquuuu08KFCy/5I2obGxsVi8XabACA7i/uBTRjxgy98cYb2rx5s37/+9+rrKxMM2fOvOhbBktKShSJRFq3IUOGxHtJAIBOKO7fB/Tggw+2/nrcuHEaP368RowYodLSUk2dOvW8/YuLi7VkyZLWj2OxGCUEANeAdn8b9vDhw5WRkaGKiooLPh8Oh5WamtpmAwB0f+1eQAcPHtSJEyc0cODA9j4UAKAL8f4SXH19fZu7mcrKSu3Zs0fp6elKT0/XSy+9pLlz5yo7O1v79+/Xs88+q5EjR2r69OlxXTgAoGvzLqCdO3e2mVH2w+s38+bN04oVK7R371797W9/U21trXJycjRt2jT99re/DTQfCQDQfXkX0B133HHJQXP//Oc/r2pBQYVCIe/MlQ7MsxJkSGiQTJBBiFKwoay33367d6agoMA7M2zYMO+MJP39738PlOusxowZEyi3Z88e78x3333nnfnvf//rnQnyn9mggzt79erlnemozytB/v1JwdbHMFIAQLdCAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADAR9x/JbSXIhNcgE7SlYJN1ExL8u/4///mPd+ZiP3n2UkaOHOmdkaQ5c+Z4ZzZt2uSdKS4u9s4E/bHud999t3cmyMTpl19+2TuTm5vrnQn6d/vvf//bO1NXV+edCTLROTk52TsTdEL1mTNnvDNBpsv37NnTOxPUsWPHvDNBJ+ZfDndAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATIRc0Cl97SQWiykSiXTIsYIMCJWCDeYLMkjypz/9qXemurraO7Nnzx7vTGd30003BcqNGzfOOxNkoGaQgbanTp3yzgS5HqRgQzh79+7tnemocxd08HCQf+tB1tfU1OSd6du3r3dGCnZNfPHFF4GOFY1GlZqaetHnuQMCAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgoof1AiwFGTQY1IEDB7wzo0eP9s7ccsst3pljx455ZyTp0KFDgXIdYefOnYFy33//vXfmzjvv9M4EufYOHjzonTl79qx3RpJ69erlnQnyZ+qoTM+ePb0zQY8VZL5zcnKydybI35EkHT16NFCuPXAHBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwESnHUbat29fhUKhK95/0KBB3seIxWLemaDq6+u9M7W1td6ZxsZG78y0adO8M5L09ddfe2eqq6u9MydPnvTOZGRkeGckaejQod6ZIANMv/vuO+9MkIGaKSkp3hlJSkjw/79pU1OTdybI4M4g56G5udk7I0mnT5/2zvTo4f9pNcj5DjpMORqNBsq1B+6AAAAmKCAAgAmvAiopKdHNN9+slJQUZWZmavbs2SovL2+zz+nTp1VUVKT+/furb9++mjt3rmpqauK6aABA1+dVQGVlZSoqKtK2bdu0adMmnTlzRtOmTVNDQ0PrPk899ZTef/99vfvuuyorK9Phw4c1Z86cuC8cANC1eb1atnHjxjYfr1q1SpmZmdq1a5emTJmiaDSqv/71r1q9erXuuusuSdLKlSv1k5/8RNu2bQv00zoBAN3TVb0G9MO7KdLT0yVJu3bt0pkzZ1RYWNi6z5gxY5Sbm6utW7de8PdobGxULBZrswEAur/ABdTS0qLFixdr8uTJGjt2rKRzb7FNTk5WWlpam32zsrIu+vbbkpISRSKR1m3IkCFBlwQA6EICF1BRUZG+/PJLrV279qoWUFxcrGg02rpVVVVd1e8HAOgaAn0j6qJFi/TBBx9oy5YtGjx4cOvj2dnZampqUm1tbZu7oJqaGmVnZ1/w9wqHwwqHw0GWAQDowrzugJxzWrRokdatW6ePPvpIeXl5bZ6fOHGikpKStHnz5tbHysvLdeDAARUUFMRnxQCAbsHrDqioqEirV6/Whg0blJKS0vq6TiQSUa9evRSJRPTYY49pyZIlSk9PV2pqqp588kkVFBTwDjgAQBteBbRixQpJ0h133NHm8ZUrV2r+/PmSpD/84Q9KSEjQ3Llz1djYqOnTp+vPf/5zXBYLAOg+Qi7INMB2FIvFFIlElJ2d7TWgb/Lkyd7HCjIgVDp3x+frf79Z90oFGSw6bNgw70zQS+D48ePemaSkJO9MkCGXPoNs/1eQ4ZMnTpzwzgQZWNm3b1/vTNCBlUHWF+R6DfJ327t3b+/M2bNnvTOSdObMGe9MkGGpHXUeJLV5ieRKBTkP0rlv1UlNTb3o88yCAwCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYCPQTUTtCNBr1mmh86NAh72PU1tZ6Z6RgU2h9Jnv/IMhE5/Lycu9MkLUFlZyc7J0JMsm4rq7OOyMFO+dBJkcHOQ9Bpo8H/bsNMiG9o87dyZMnvTNBBTkPQa7XIFPLg0wfl4JPtm4P3AEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAw0WmHkfbo0cNruGG/fv28j9G3b1/vjBRsCGDQwYG+6uvrvTOJiYmBjhVkoOapU6cCHctX0CGcaWlp8V3IRQQ5dxkZGe2wkgtLSkryzjQ3N3tnggwwDTKMNMi/C0nq2bOnd+bYsWPemSCfv4Kcu86GOyAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmOu0w0rq6Oq/9d+zY4X2M9PR074wkZWVleWeCDDUMMhgzyHGCDHeUpHA47J0JMvjUOeedaWpq8s5IwYZwnjlzxjsTZGBlEEGHcAbRo4f/p5OzZ896Z4IMci0oKPDOSMGGhDY0NHhncnNzvTOffPKJd6az4Q4IAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACAiZALMumxHcViMUUiEetlAACuUjQaVWpq6kWf5w4IAGCCAgIAmPAqoJKSEt18881KSUlRZmamZs+erfLy8jb73HHHHQqFQm22BQsWxHXRAICuz6uAysrKVFRUpG3btmnTpk06c+aMpk2bdt4PYHr88cd15MiR1m3ZsmVxXTQAoOvz+hGGGzdubPPxqlWrlJmZqV27dmnKlCmtj/fu3VvZ2dnxWSEAoFu6qteAotGopPN/tPVbb72ljIwMjR07VsXFxZf8kc+NjY2KxWJtNgDANcAF1Nzc7O655x43efLkNo//5S9/cRs3bnR79+51b775phs0aJC77777Lvr7LF261EliY2NjY+tmWzQavWSPBC6gBQsWuKFDh7qqqqpL7rd582YnyVVUVFzw+dOnT7toNNq6VVVVmZ80NjY2Nrar3y5XQF6vAf1g0aJF+uCDD7RlyxYNHjz4kvvm5+dLkioqKjRixIjzng+HwwqHw0GWAQDowrwKyDmnJ598UuvWrVNpaany8vIum9mzZ48kaeDAgYEWCADonrwKqKioSKtXr9aGDRuUkpKi6upqSVIkElGvXr20f/9+rV69Wnfffbf69++vvXv36qmnntKUKVM0fvz4dvkDAAC6KJ/XfXSRr/OtXLnSOefcgQMH3JQpU1x6eroLh8Nu5MiR7plnnrns1wH/VzQaNf+6JRsbGxvb1W+X+9zPMFIAQLtgGCkAoFOigAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJjodAXknLNeAgAgDi73+bzTFVBdXZ31EgAAcXC5z+ch18luOVpaWnT48GGlpKQoFAq1eS4Wi2nIkCGqqqpSamqq0QrtcR7O4Tycw3k4h/NwTmc4D8451dXVKScnRwkJF7/P6dGBa7oiCQkJGjx48CX3SU1NvaYvsB9wHs7hPJzDeTiH83CO9XmIRCKX3afTfQkOAHBtoIAAACa6VAGFw2EtXbpU4XDYeimmOA/ncB7O4Tycw3k4pyudh073JgQAwLWhS90BAQC6DwoIAGCCAgIAmKCAAAAmukwBLV++XMOGDVPPnj2Vn5+vHTt2WC+pw7344osKhUJttjFjxlgvq91t2bJFs2bNUk5OjkKhkNavX9/meeecXnjhBQ0cOFC9evVSYWGh9u3bZ7PYdnS58zB//vzzro8ZM2bYLLadlJSU6Oabb1ZKSooyMzM1e/ZslZeXt9nn9OnTKioqUv/+/dW3b1/NnTtXNTU1RituH1dyHu64447zrocFCxYYrfjCukQBvf3221qyZImWLl2qzz//XBMmTND06dN19OhR66V1uOuvv15Hjhxp3T799FPrJbW7hoYGTZgwQcuXL7/g88uWLdNrr72m119/Xdu3b1efPn00ffp0nT59uoNX2r4udx4kacaMGW2ujzVr1nTgCttfWVmZioqKtG3bNm3atElnzpzRtGnT1NDQ0LrPU089pffff1/vvvuuysrKdPjwYc2ZM8dw1fF3JedBkh5//PE218OyZcuMVnwRrguYNGmSKyoqav24ubnZ5eTkuJKSEsNVdbylS5e6CRMmWC/DlCS3bt261o9bWlpcdna2e+WVV1ofq62tdeFw2K1Zs8ZghR3jx+fBOefmzZvn7r33XpP1WDl69KiT5MrKypxz5/7uk5KS3Lvvvtu6z9dff+0kua1bt1ots939+Dw459ztt9/ufvGLX9gt6gp0+jugpqYm7dq1S4WFha2PJSQkqLCwUFu3bjVcmY19+/YpJydHw4cP1yOPPKIDBw5YL8lUZWWlqqur21wfkUhE+fn51+T1UVpaqszMTF133XVauHChTpw4Yb2kdhWNRiVJ6enpkqRdu3bpzJkzba6HMWPGKDc3t1tfDz8+Dz946623lJGRobFjx6q4uFgnT560WN5FdbphpD92/PhxNTc3Kysrq83jWVlZ+uabb4xWZSM/P1+rVq3SddddpyNHjuill17Sbbfdpi+//FIpKSnWyzNRXV0tSRe8Pn547loxY8YMzZkzR3l5edq/f79+/etfa+bMmdq6dasSExOtlxd3LS0tWrx4sSZPnqyxY8dKOnc9JCcnKy0trc2+3fl6uNB5kKSHH35YQ4cOVU5Ojvbu3atf/epXKi8v13vvvWe42rY6fQHh/82cObP11+PHj1d+fr6GDh2qd955R4899pjhytAZPPjgg62/HjdunMaPH68RI0aotLRUU6dONVxZ+ygqKtKXX355TbwOeikXOw9PPPFE66/HjRungQMHaurUqdq/f79GjBjR0cu8oE7/JbiMjAwlJiae9y6WmpoaZWdnG62qc0hLS9Po0aNVUVFhvRQzP1wDXB/nGz58uDIyMrrl9bFo0SJ98MEH+vjjj9v8+Jbs7Gw1NTWptra2zf7d9Xq42Hm4kPz8fEnqVNdDpy+g5ORkTZw4UZs3b259rKWlRZs3b1ZBQYHhyuzV19dr//79GjhwoPVSzOTl5Sk7O7vN9RGLxbR9+/Zr/vo4ePCgTpw40a2uD+ecFi1apHXr1umjjz5SXl5em+cnTpyopKSkNtdDeXm5Dhw40K2uh8udhwvZs2ePJHWu68H6XRBXYu3atS4cDrtVq1a5r776yj3xxBMuLS3NVVdXWy+tQ/3yl790paWlrrKy0n322WeusLDQZWRkuKNHj1ovrV3V1dW53bt3u927dztJ7tVXX3W7d+923333nXPOud/97ncuLS3Nbdiwwe3du9fde++9Li8vz506dcp45fF1qfNQV1fnnn76abd161ZXWVnpPvzwQ3fjjTe6UaNGudOnT1svPW4WLlzoIpGIKy0tdUeOHGndTp482brPggULXG5urvvoo4/czp07XUFBgSsoKDBcdfxd7jxUVFS43/zmN27nzp2usrLSbdiwwQ0fPtxNmTLFeOVtdYkCcs65P/3pTy43N9clJye7SZMmuW3btlkvqcM98MADbuDAgS45OdkNGjTIPfDAA66iosJ6We3u448/dpLO2+bNm+ecO/dW7Oeff95lZWW5cDjspk6d6srLy20X3Q4udR5Onjzppk2b5gYMGOCSkpLc0KFD3eOPP97t/pN2oT+/JLdy5crWfU6dOuV+9rOfuX79+rnevXu7++67zx05csRu0e3gcufhwIEDbsqUKS49Pd2Fw2E3cuRI98wzz7hoNGq78B/hxzEAAEx0+teAAADdEwUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABP/B07SaG0h62d2AAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "image, label = train_data[0]\n",
        "print(image.shape, label)\n",
        "plt.imshow(image[0], cmap = 'gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFGPmPXTT5i1"
      },
      "source": [
        "2. Recreate the LeNet-5 architecture as your baseline. The model takes as input a greyscale image of size 28x28x1 and has 10 outputs, one for each class. Make sure all parameters (number of neurons, number and size of kernels) is the same as in the original architecture. You may assume that no zero-padding was applied. The model is trained using cross-entropy loss, Adam optimizer with a learning rate of 0.001. Use torch.nn.init.kaiming_uniform to initialize your weights. Use a batch size of 32, unless your hardware doesn't allow you to. Then reduce the size accordingly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BnWpAn0T9XS",
        "outputId": "10a5e100-58b6-4c30-eceb-94a405d5f53f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.nn.init import kaiming_uniform_, zeros_\n",
        "\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        # Convolutional and pooling layers\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2),  # 1 input channel, 6 output channels, 5x5 kernel\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5), # 6 input channels, 16 output channels, 5x5 kernel\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        # Fully connected layers\n",
        "        self.dense = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(16 * 5 * 5, 120),  # 16 channels, 5x5 feature map size \n",
        "            #NOTE: isn't this supposed to be 16*5*5?\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(120, 84),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(84, 10),  # 10 output classes\n",
        "        )\n",
        "\n",
        "        self.apply(self.weights_init)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Convolutional layers with ReLU activation and max pooling\n",
        "        x = self.conv(x)\n",
        "        # Fully connected layers with ReLU activation\n",
        "        y = self.dense(x)\n",
        "        return y\n",
        "\n",
        "    def weights_init(self, m):\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            torch.nn.init.kaiming_uniform_(m.weight)\n",
        "            torch.nn.init.zeros_(m.bias)\n",
        "        if isinstance(m, nn.Linear):\n",
        "            torch.nn.init.kaiming_uniform_(m.weight)\n",
        "            torch.nn.init.zeros_(m.bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------\n",
            "Layer (type)                            Output Shape              Param #\n",
            "==========================================================================\n",
            "Conv2d-1                             [-1, 6, 28, 28]                  156\n",
            "ReLU-2                               [-1, 6, 28, 28]                    0\n",
            "AvgPool2d-3                          [-1, 6, 14, 14]                    0\n",
            "Conv2d-4                            [-1, 16, 10, 10]                2,416\n",
            "ReLU-5                              [-1, 16, 10, 10]                    0\n",
            "AvgPool2d-6                           [-1, 16, 5, 5]                    0\n",
            "Flatten-7                                  [-1, 400]                    0\n",
            "Linear-8                                   [-1, 120]               48,120\n",
            "ReLU-9                                     [-1, 120]                    0\n",
            "Linear-10                                   [-1, 84]               10,164\n",
            "ReLU-11                                     [-1, 84]                    0\n",
            "Linear-12                                   [-1, 10]                  850\n",
            "==========================================================================\n",
            "Total params: 61,706\n",
            "Trainable params: 61,706\n",
            "Non-trainable params: 0\n",
            "--------------------------------------------------------------------------\n",
            "Input size (MB): 0.002991\n",
            "Forward/backward pass size (MB): 0.114456\n",
            "Params size (MB): 0.235390\n",
            "Estimated Total Size (MB): 0.352837\n",
            "--------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchkeras import summary\n",
        "\n",
        "model = LeNet5()\n",
        "\n",
        "def check_weights():\n",
        "    for param in model.parameters():\n",
        "        print(param.data)\n",
        "\n",
        "def summarize(model):\n",
        "    summary(model=model, input_shape=(1,28,28))\n",
        "\n",
        "summarize(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def train(loader, model, criterion, optimizer):\n",
        "    size = len(loader.dataset)\n",
        "    batches = len(loader)\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    total_loss = 0\n",
        "\n",
        "    for n, batch in enumerate(tqdm(loader)):\n",
        "        X,y = batch\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        pred = model(X)\n",
        "        loss = criterion(pred, y)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def test(loader, model, criterion):\n",
        "    size = len(loader.dataset)\n",
        "    batches = len(loader)\n",
        "    total_loss = 0\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            X,y = batch\n",
        "            pred = model(X)\n",
        "            \n",
        "            loss = criterion(pred, y)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            y = y.data.numpy()\n",
        "            y_true.extend(y)\n",
        "            pred = pred.argmax(1).data.numpy()\n",
        "            y_pred.extend(pred)\n",
        "\n",
        "    loss = total_loss / batches\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    print(f\"loss: {loss}\\naccuracy: {accuracy}\")\n",
        "    return y_true, y_pred, loss\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "\n",
        "model = LeNet5()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 15\n",
        "losses_train = []\n",
        "losses_test = []\n",
        "\n",
        "def train_test_loop(model, criterion, optimizer, epochs):\n",
        "    for i in range(epochs):\n",
        "        print(f\"Epoch {i+1}\\n----------------\")\n",
        "        print(\"Training:\")\n",
        "        train(loader=train_dataloader, model=model, criterion=criterion, optimizer=optimizer)\n",
        "    \n",
        "        print(\"Testing (train-set):\")\n",
        "        y_true_train, y_pred_train, loss_train = test(loader=train_dataloader, model=model, criterion=criterion)\n",
        "        print(\"Testing (test set):\")\n",
        "        y_true_test, y_pred_test, loss_test = test(loader=val_dataloader, model=model, criterion=criterion)\n",
        "    \n",
        "    losses_train.append(loss_train)\n",
        "    losses_test.append(loss_test)\n",
        "    return y_true_test, y_pred_test\n",
        "\n",
        "    print(\"----------------\")\n",
        "\n",
        "classes = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"]\n",
        "\n",
        "def evaluate(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    conf_matrix = pd.DataFrame(conf_matrix, classes, classes)\n",
        "    sn.heatmap(conf_matrix, annot=True, fmt= 'g')\n",
        "    cr = classification_report(y_true, y_pred, target_names=classes)\n",
        "    print(cr)\n",
        "\n",
        "def plot_loss(train_losses, test_losses, epochs):\n",
        "    plt.plot(range(1, epochs+1), train_losses)\n",
        "    plt.plot(range(1, epochs+1), test_losses)\n",
        "    plt.show()\n",
        "\n",
        "#print(losses_train, losses_test)\n",
        "#evaluate(y_true_test,y_pred_test)\n",
        "#plot_loss(losses_train, losses_test, epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7m3tcJzWwOR"
      },
      "source": [
        "3. Now create four model variants. Each model may differ from the previous model by only one aspect, such that we can compare each pair of subsequent models pair-wise. An aspect should be a meaningful property, e.g., change the type of one layer (convolution --> pooling, etc.), add one layer, use dropout, change your activation function, change the number or size of your kernels, change the learning rate, etc. No use of any merging, attention, recurrent or locally-connected layers. Your variants should be aimed at getting a better performance. We keep the batch sizes fixed so choose a number and keep it constant for all models (including the baseline model)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-05fnwZKWx_v"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\noptions:\\n\\nDropout\\nLearning rate\\nActivation function\\nMore/Less layers\\nPooling type\\nNormalisation\\n\\nloss_fn/optimizer/weight init (I dont think this will do much)\\n\\ngrid-search?\\n'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "options:\n",
        "\n",
        "Dropout\n",
        "Learning rate (+++, 0.01 -> 0.001)\n",
        "Activation function\n",
        "More/Less layers\n",
        " - extra linear layer (+/-, 400 -> 220)\n",
        " - extra conv layer\n",
        " - more convolution kernels (++, 6->16, 16-> 26)\n",
        "Pooling type\n",
        "Normalisation\n",
        "\n",
        "loss_fn/optimizer/weight init (I dont think this will do much)\n",
        "\n",
        "grid-search?\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.nn.init import kaiming_uniform_, zeros_\n",
        "\n",
        "class Var1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Var1, self).__init__()\n",
        "        # Convolutional and pooling layers\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, padding=2),  # 1 input channel, 6 output channels, 5x5 kernel\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(in_channels=16, out_channels=26, kernel_size=5), # 6 input channels, 16 output channels, 5x5 kernel\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        # Fully connected layers\n",
        "        self.dense = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(26 * 5 * 5, 120),  # 16 channels, 5x5 feature map size \n",
        "            #NOTE: isn't this supposed to be 16*5*5?\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(120, 84),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(84, 10),  # 10 output classes\n",
        "        )\n",
        "\n",
        "        self.apply(self.weights_init)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Convolutional layers with ReLU activation and max pooling\n",
        "        x = self.conv(x)\n",
        "        # Fully connected layers with ReLU activation\n",
        "        y = self.dense(x)\n",
        "        return y\n",
        "\n",
        "    def weights_init(self, m):\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            torch.nn.init.kaiming_uniform_(m.weight)\n",
        "            torch.nn.init.zeros_(m.bias)\n",
        "        if isinstance(m, nn.Linear):\n",
        "            torch.nn.init.kaiming_uniform_(m.weight)\n",
        "            torch.nn.init.zeros_(m.bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "----------------\n",
            "Training:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:29<00:00, 52.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing (train-set):\n",
            "loss: 0.3537599188552708\n",
            "accuracy: 0.86696\n",
            "Testing (test set):\n",
            "loss: 0.3700416944325922\n",
            "accuracy: 0.8635\n",
            "Epoch 2\n",
            "----------------\n",
            "Training:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:31<00:00, 49.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing (train-set):\n",
            "loss: 0.2794161811685493\n",
            "accuracy: 0.89808\n",
            "Testing (test set):\n",
            "loss: 0.30048965591306503\n",
            "accuracy: 0.891\n",
            "Epoch 3\n",
            "----------------\n",
            "Training:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:31<00:00, 49.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing (train-set):\n",
            "loss: 0.24359350828352602\n",
            "accuracy: 0.91244\n",
            "Testing (test set):\n",
            "loss: 0.27847238696706944\n",
            "accuracy: 0.9008\n",
            "Epoch 4\n",
            "----------------\n",
            "Training:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:31<00:00, 50.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing (train-set):\n",
            "loss: 0.22167305914674404\n",
            "accuracy: 0.91782\n",
            "Testing (test set):\n",
            "loss: 0.2709693679461083\n",
            "accuracy: 0.9045\n",
            "Epoch 5\n",
            "----------------\n",
            "Training:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:31<00:00, 49.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing (train-set):\n",
            "loss: 0.20830174418933742\n",
            "accuracy: 0.92212\n",
            "Testing (test set):\n",
            "loss: 0.27239460402284377\n",
            "accuracy: 0.9062\n",
            "Epoch 6\n",
            "----------------\n",
            "Training:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:31<00:00, 50.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing (train-set):\n",
            "loss: 0.18063719343854043\n",
            "accuracy: 0.93326\n",
            "Testing (test set):\n",
            "loss: 0.2449706261709761\n",
            "accuracy: 0.9126\n",
            "Epoch 7\n",
            "----------------\n",
            "Training:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:31<00:00, 49.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing (train-set):\n",
            "loss: 0.19221033279141095\n",
            "accuracy: 0.92688\n",
            "Testing (test set):\n",
            "loss: 0.27516691105815166\n",
            "accuracy: 0.9026\n",
            "Epoch 8\n",
            "----------------\n",
            "Training:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:31<00:00, 49.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing (train-set):\n",
            "loss: 0.15728868843638413\n",
            "accuracy: 0.94126\n",
            "Testing (test set):\n",
            "loss: 0.24458590276039446\n",
            "accuracy: 0.9128\n",
            "Epoch 9\n",
            "----------------\n",
            "Training:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:31<00:00, 49.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing (train-set):\n",
            "loss: 0.17692372099313497\n",
            "accuracy: 0.93206\n",
            "Testing (test set):\n",
            "loss: 0.28044097680158125\n",
            "accuracy: 0.905\n",
            "Epoch 10\n",
            "----------------\n",
            "Training:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:31<00:00, 49.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing (train-set):\n",
            "loss: 0.13818484163525505\n",
            "accuracy: 0.94854\n",
            "Testing (test set):\n",
            "loss: 0.2560162954091931\n",
            "accuracy: 0.9141\n",
            "Epoch 11\n",
            "----------------\n",
            "Training:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:32<00:00, 48.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing (train-set):\n",
            "loss: 0.12117540622302835\n",
            "accuracy: 0.95494\n",
            "Testing (test set):\n",
            "loss: 0.26105395485810673\n",
            "accuracy: 0.9132\n",
            "Epoch 12\n",
            "----------------\n",
            "Training:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:30<00:00, 50.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing (train-set):\n",
            "loss: 0.12406152456442296\n",
            "accuracy: 0.95406\n",
            "Testing (test set):\n",
            "loss: 0.26897742317322965\n",
            "accuracy: 0.9107\n",
            "Epoch 13\n",
            "----------------\n",
            "Training:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:31<00:00, 49.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing (train-set):\n",
            "loss: 0.1036748029112873\n",
            "accuracy: 0.96062\n",
            "Testing (test set):\n",
            "loss: 0.2805904874212879\n",
            "accuracy: 0.9122\n",
            "Epoch 14\n",
            "----------------\n",
            "Training:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:33<00:00, 46.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing (train-set):\n",
            "loss: 0.08768384928680403\n",
            "accuracy: 0.96844\n",
            "Testing (test set):\n",
            "loss: 0.27633855246511785\n",
            "accuracy: 0.918\n",
            "Epoch 15\n",
            "----------------\n",
            "Training:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:33<00:00, 46.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing (train-set):\n",
            "loss: 0.09573303788640582\n",
            "accuracy: 0.96418\n",
            "Testing (test set):\n",
            "loss: 0.29196324082055747\n",
            "accuracy: 0.9128\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "([5,\n",
              "  7,\n",
              "  5,\n",
              "  5,\n",
              "  9,\n",
              "  1,\n",
              "  7,\n",
              "  2,\n",
              "  3,\n",
              "  3,\n",
              "  1,\n",
              "  6,\n",
              "  9,\n",
              "  4,\n",
              "  7,\n",
              "  2,\n",
              "  5,\n",
              "  8,\n",
              "  3,\n",
              "  1,\n",
              "  2,\n",
              "  6,\n",
              "  7,\n",
              "  3,\n",
              "  0,\n",
              "  2,\n",
              "  5,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  9,\n",
              "  5,\n",
              "  5,\n",
              "  3,\n",
              "  6,\n",
              "  4,\n",
              "  0,\n",
              "  3,\n",
              "  1,\n",
              "  7,\n",
              "  5,\n",
              "  7,\n",
              "  3,\n",
              "  5,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  6,\n",
              "  6,\n",
              "  8,\n",
              "  4,\n",
              "  8,\n",
              "  9,\n",
              "  2,\n",
              "  3,\n",
              "  8,\n",
              "  4,\n",
              "  4,\n",
              "  9,\n",
              "  1,\n",
              "  0,\n",
              "  6,\n",
              "  0,\n",
              "  7,\n",
              "  3,\n",
              "  5,\n",
              "  9,\n",
              "  8,\n",
              "  5,\n",
              "  7,\n",
              "  1,\n",
              "  4,\n",
              "  4,\n",
              "  1,\n",
              "  6,\n",
              "  9,\n",
              "  9,\n",
              "  3,\n",
              "  9,\n",
              "  1,\n",
              "  5,\n",
              "  4,\n",
              "  6,\n",
              "  1,\n",
              "  7,\n",
              "  6,\n",
              "  8,\n",
              "  6,\n",
              "  8,\n",
              "  1,\n",
              "  0,\n",
              "  5,\n",
              "  2,\n",
              "  0,\n",
              "  8,\n",
              "  0,\n",
              "  3,\n",
              "  9,\n",
              "  1,\n",
              "  6,\n",
              "  1,\n",
              "  1,\n",
              "  5,\n",
              "  6,\n",
              "  5,\n",
              "  9,\n",
              "  8,\n",
              "  4,\n",
              "  6,\n",
              "  0,\n",
              "  6,\n",
              "  0,\n",
              "  8,\n",
              "  5,\n",
              "  3,\n",
              "  8,\n",
              "  5,\n",
              "  6,\n",
              "  1,\n",
              "  1,\n",
              "  8,\n",
              "  2,\n",
              "  2,\n",
              "  7,\n",
              "  0,\n",
              "  0,\n",
              "  7,\n",
              "  1,\n",
              "  7,\n",
              "  8,\n",
              "  5,\n",
              "  2,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  7,\n",
              "  9,\n",
              "  9,\n",
              "  3,\n",
              "  5,\n",
              "  9,\n",
              "  0,\n",
              "  7,\n",
              "  6,\n",
              "  0,\n",
              "  8,\n",
              "  6,\n",
              "  2,\n",
              "  0,\n",
              "  9,\n",
              "  2,\n",
              "  7,\n",
              "  6,\n",
              "  1,\n",
              "  4,\n",
              "  8,\n",
              "  7,\n",
              "  2,\n",
              "  4,\n",
              "  3,\n",
              "  7,\n",
              "  0,\n",
              "  9,\n",
              "  9,\n",
              "  5,\n",
              "  4,\n",
              "  7,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  8,\n",
              "  3,\n",
              "  4,\n",
              "  6,\n",
              "  3,\n",
              "  4,\n",
              "  6,\n",
              "  3,\n",
              "  6,\n",
              "  8,\n",
              "  8,\n",
              "  2,\n",
              "  2,\n",
              "  9,\n",
              "  4,\n",
              "  9,\n",
              "  5,\n",
              "  1,\n",
              "  5,\n",
              "  8,\n",
              "  7,\n",
              "  2,\n",
              "  9,\n",
              "  3,\n",
              "  5,\n",
              "  8,\n",
              "  0,\n",
              "  5,\n",
              "  5,\n",
              "  9,\n",
              "  7,\n",
              "  5,\n",
              "  8,\n",
              "  4,\n",
              "  0,\n",
              "  4,\n",
              "  3,\n",
              "  0,\n",
              "  8,\n",
              "  3,\n",
              "  4,\n",
              "  8,\n",
              "  0,\n",
              "  4,\n",
              "  9,\n",
              "  4,\n",
              "  7,\n",
              "  2,\n",
              "  0,\n",
              "  5,\n",
              "  9,\n",
              "  5,\n",
              "  5,\n",
              "  3,\n",
              "  5,\n",
              "  0,\n",
              "  6,\n",
              "  0,\n",
              "  8,\n",
              "  6,\n",
              "  4,\n",
              "  5,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  9,\n",
              "  8,\n",
              "  7,\n",
              "  6,\n",
              "  5,\n",
              "  1,\n",
              "  4,\n",
              "  8,\n",
              "  5,\n",
              "  1,\n",
              "  4,\n",
              "  3,\n",
              "  2,\n",
              "  6,\n",
              "  5,\n",
              "  7,\n",
              "  8,\n",
              "  6,\n",
              "  3,\n",
              "  6,\n",
              "  1,\n",
              "  7,\n",
              "  6,\n",
              "  9,\n",
              "  0,\n",
              "  6,\n",
              "  1,\n",
              "  4,\n",
              "  8,\n",
              "  5,\n",
              "  2,\n",
              "  4,\n",
              "  9,\n",
              "  8,\n",
              "  8,\n",
              "  6,\n",
              "  4,\n",
              "  8,\n",
              "  9,\n",
              "  9,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  9,\n",
              "  7,\n",
              "  7,\n",
              "  8,\n",
              "  4,\n",
              "  4,\n",
              "  9,\n",
              "  2,\n",
              "  1,\n",
              "  5,\n",
              "  9,\n",
              "  3,\n",
              "  9,\n",
              "  8,\n",
              "  3,\n",
              "  9,\n",
              "  3,\n",
              "  5,\n",
              "  9,\n",
              "  0,\n",
              "  4,\n",
              "  9,\n",
              "  8,\n",
              "  4,\n",
              "  1,\n",
              "  6,\n",
              "  5,\n",
              "  4,\n",
              "  4,\n",
              "  8,\n",
              "  3,\n",
              "  6,\n",
              "  8,\n",
              "  0,\n",
              "  9,\n",
              "  1,\n",
              "  4,\n",
              "  8,\n",
              "  2,\n",
              "  1,\n",
              "  4,\n",
              "  3,\n",
              "  8,\n",
              "  5,\n",
              "  4,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  9,\n",
              "  1,\n",
              "  0,\n",
              "  5,\n",
              "  6,\n",
              "  5,\n",
              "  0,\n",
              "  5,\n",
              "  8,\n",
              "  5,\n",
              "  6,\n",
              "  8,\n",
              "  6,\n",
              "  4,\n",
              "  6,\n",
              "  2,\n",
              "  4,\n",
              "  8,\n",
              "  8,\n",
              "  6,\n",
              "  4,\n",
              "  8,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  3,\n",
              "  3,\n",
              "  2,\n",
              "  0,\n",
              "  7,\n",
              "  2,\n",
              "  7,\n",
              "  4,\n",
              "  1,\n",
              "  1,\n",
              "  6,\n",
              "  5,\n",
              "  1,\n",
              "  7,\n",
              "  7,\n",
              "  2,\n",
              "  9,\n",
              "  3,\n",
              "  5,\n",
              "  1,\n",
              "  9,\n",
              "  0,\n",
              "  3,\n",
              "  8,\n",
              "  4,\n",
              "  0,\n",
              "  9,\n",
              "  7,\n",
              "  4,\n",
              "  7,\n",
              "  2,\n",
              "  1,\n",
              "  2,\n",
              "  6,\n",
              "  2,\n",
              "  5,\n",
              "  4,\n",
              "  1,\n",
              "  9,\n",
              "  3,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  8,\n",
              "  8,\n",
              "  8,\n",
              "  1,\n",
              "  9,\n",
              "  4,\n",
              "  1,\n",
              "  3,\n",
              "  4,\n",
              "  7,\n",
              "  6,\n",
              "  6,\n",
              "  8,\n",
              "  3,\n",
              "  1,\n",
              "  5,\n",
              "  3,\n",
              "  7,\n",
              "  9,\n",
              "  0,\n",
              "  7,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  6,\n",
              "  9,\n",
              "  5,\n",
              "  4,\n",
              "  6,\n",
              "  5,\n",
              "  1,\n",
              "  9,\n",
              "  5,\n",
              "  7,\n",
              "  8,\n",
              "  4,\n",
              "  1,\n",
              "  7,\n",
              "  8,\n",
              "  7,\n",
              "  3,\n",
              "  7,\n",
              "  8,\n",
              "  9,\n",
              "  2,\n",
              "  7,\n",
              "  2,\n",
              "  7,\n",
              "  2,\n",
              "  5,\n",
              "  4,\n",
              "  1,\n",
              "  7,\n",
              "  9,\n",
              "  0,\n",
              "  4,\n",
              "  2,\n",
              "  4,\n",
              "  2,\n",
              "  3,\n",
              "  0,\n",
              "  7,\n",
              "  3,\n",
              "  8,\n",
              "  8,\n",
              "  9,\n",
              "  0,\n",
              "  4,\n",
              "  0,\n",
              "  0,\n",
              "  6,\n",
              "  7,\n",
              "  1,\n",
              "  6,\n",
              "  7,\n",
              "  4,\n",
              "  7,\n",
              "  2,\n",
              "  5,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  6,\n",
              "  7,\n",
              "  7,\n",
              "  3,\n",
              "  6,\n",
              "  4,\n",
              "  1,\n",
              "  2,\n",
              "  3,\n",
              "  9,\n",
              "  6,\n",
              "  1,\n",
              "  7,\n",
              "  6,\n",
              "  3,\n",
              "  0,\n",
              "  4,\n",
              "  3,\n",
              "  7,\n",
              "  8,\n",
              "  2,\n",
              "  3,\n",
              "  3,\n",
              "  2,\n",
              "  9,\n",
              "  8,\n",
              "  7,\n",
              "  0,\n",
              "  7,\n",
              "  5,\n",
              "  7,\n",
              "  5,\n",
              "  3,\n",
              "  5,\n",
              "  2,\n",
              "  1,\n",
              "  3,\n",
              "  1,\n",
              "  2,\n",
              "  9,\n",
              "  6,\n",
              "  3,\n",
              "  7,\n",
              "  2,\n",
              "  7,\n",
              "  4,\n",
              "  5,\n",
              "  3,\n",
              "  1,\n",
              "  2,\n",
              "  3,\n",
              "  9,\n",
              "  5,\n",
              "  2,\n",
              "  2,\n",
              "  7,\n",
              "  9,\n",
              "  9,\n",
              "  3,\n",
              "  6,\n",
              "  7,\n",
              "  3,\n",
              "  4,\n",
              "  1,\n",
              "  7,\n",
              "  8,\n",
              "  1,\n",
              "  7,\n",
              "  2,\n",
              "  7,\n",
              "  0,\n",
              "  5,\n",
              "  9,\n",
              "  4,\n",
              "  4,\n",
              "  7,\n",
              "  7,\n",
              "  1,\n",
              "  5,\n",
              "  0,\n",
              "  4,\n",
              "  9,\n",
              "  7,\n",
              "  1,\n",
              "  4,\n",
              "  6,\n",
              "  4,\n",
              "  6,\n",
              "  0,\n",
              "  2,\n",
              "  8,\n",
              "  7,\n",
              "  9,\n",
              "  2,\n",
              "  5,\n",
              "  9,\n",
              "  6,\n",
              "  5,\n",
              "  7,\n",
              "  4,\n",
              "  7,\n",
              "  2,\n",
              "  1,\n",
              "  9,\n",
              "  4,\n",
              "  8,\n",
              "  2,\n",
              "  1,\n",
              "  4,\n",
              "  2,\n",
              "  2,\n",
              "  9,\n",
              "  0,\n",
              "  2,\n",
              "  4,\n",
              "  8,\n",
              "  8,\n",
              "  5,\n",
              "  8,\n",
              "  2,\n",
              "  3,\n",
              "  5,\n",
              "  0,\n",
              "  9,\n",
              "  9,\n",
              "  2,\n",
              "  0,\n",
              "  7,\n",
              "  8,\n",
              "  2,\n",
              "  1,\n",
              "  4,\n",
              "  6,\n",
              "  0,\n",
              "  7,\n",
              "  3,\n",
              "  0,\n",
              "  9,\n",
              "  9,\n",
              "  2,\n",
              "  5,\n",
              "  6,\n",
              "  4,\n",
              "  8,\n",
              "  8,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  2,\n",
              "  0,\n",
              "  5,\n",
              "  5,\n",
              "  1,\n",
              "  4,\n",
              "  2,\n",
              "  7,\n",
              "  0,\n",
              "  3,\n",
              "  3,\n",
              "  4,\n",
              "  2,\n",
              "  0,\n",
              "  2,\n",
              "  3,\n",
              "  1,\n",
              "  2,\n",
              "  6,\n",
              "  6,\n",
              "  4,\n",
              "  5,\n",
              "  8,\n",
              "  9,\n",
              "  0,\n",
              "  8,\n",
              "  0,\n",
              "  8,\n",
              "  4,\n",
              "  2,\n",
              "  8,\n",
              "  3,\n",
              "  8,\n",
              "  0,\n",
              "  2,\n",
              "  4,\n",
              "  5,\n",
              "  3,\n",
              "  7,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  3,\n",
              "  8,\n",
              "  2,\n",
              "  9,\n",
              "  5,\n",
              "  8,\n",
              "  9,\n",
              "  4,\n",
              "  2,\n",
              "  8,\n",
              "  8,\n",
              "  6,\n",
              "  6,\n",
              "  8,\n",
              "  9,\n",
              "  5,\n",
              "  6,\n",
              "  8,\n",
              "  4,\n",
              "  1,\n",
              "  5,\n",
              "  8,\n",
              "  3,\n",
              "  1,\n",
              "  2,\n",
              "  9,\n",
              "  6,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  9,\n",
              "  5,\n",
              "  5,\n",
              "  1,\n",
              "  2,\n",
              "  7,\n",
              "  8,\n",
              "  0,\n",
              "  2,\n",
              "  8,\n",
              "  0,\n",
              "  7,\n",
              "  0,\n",
              "  3,\n",
              "  8,\n",
              "  6,\n",
              "  9,\n",
              "  1,\n",
              "  4,\n",
              "  2,\n",
              "  4,\n",
              "  6,\n",
              "  2,\n",
              "  5,\n",
              "  1,\n",
              "  7,\n",
              "  1,\n",
              "  7,\n",
              "  0,\n",
              "  9,\n",
              "  7,\n",
              "  4,\n",
              "  5,\n",
              "  3,\n",
              "  0,\n",
              "  8,\n",
              "  5,\n",
              "  9,\n",
              "  4,\n",
              "  9,\n",
              "  3,\n",
              "  8,\n",
              "  6,\n",
              "  0,\n",
              "  1,\n",
              "  7,\n",
              "  3,\n",
              "  9,\n",
              "  2,\n",
              "  6,\n",
              "  0,\n",
              "  4,\n",
              "  9,\n",
              "  4,\n",
              "  5,\n",
              "  7,\n",
              "  8,\n",
              "  6,\n",
              "  2,\n",
              "  7,\n",
              "  3,\n",
              "  7,\n",
              "  4,\n",
              "  9,\n",
              "  8,\n",
              "  7,\n",
              "  8,\n",
              "  3,\n",
              "  8,\n",
              "  8,\n",
              "  3,\n",
              "  4,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  7,\n",
              "  1,\n",
              "  4,\n",
              "  3,\n",
              "  8,\n",
              "  2,\n",
              "  1,\n",
              "  3,\n",
              "  8,\n",
              "  6,\n",
              "  3,\n",
              "  2,\n",
              "  4,\n",
              "  7,\n",
              "  7,\n",
              "  2,\n",
              "  2,\n",
              "  8,\n",
              "  8,\n",
              "  6,\n",
              "  5,\n",
              "  9,\n",
              "  2,\n",
              "  6,\n",
              "  7,\n",
              "  9,\n",
              "  0,\n",
              "  4,\n",
              "  6,\n",
              "  2,\n",
              "  7,\n",
              "  1,\n",
              "  6,\n",
              "  8,\n",
              "  2,\n",
              "  0,\n",
              "  4,\n",
              "  0,\n",
              "  1,\n",
              "  7,\n",
              "  8,\n",
              "  5,\n",
              "  5,\n",
              "  1,\n",
              "  8,\n",
              "  9,\n",
              "  1,\n",
              "  7,\n",
              "  4,\n",
              "  6,\n",
              "  1,\n",
              "  3,\n",
              "  6,\n",
              "  5,\n",
              "  6,\n",
              "  1,\n",
              "  5,\n",
              "  8,\n",
              "  3,\n",
              "  2,\n",
              "  7,\n",
              "  0,\n",
              "  1,\n",
              "  3,\n",
              "  2,\n",
              "  7,\n",
              "  2,\n",
              "  5,\n",
              "  4,\n",
              "  2,\n",
              "  0,\n",
              "  3,\n",
              "  3,\n",
              "  4,\n",
              "  1,\n",
              "  8,\n",
              "  6,\n",
              "  7,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  4,\n",
              "  6,\n",
              "  3,\n",
              "  1,\n",
              "  0,\n",
              "  9,\n",
              "  4,\n",
              "  5,\n",
              "  3,\n",
              "  3,\n",
              "  7,\n",
              "  1,\n",
              "  5,\n",
              "  9,\n",
              "  3,\n",
              "  9,\n",
              "  3,\n",
              "  6,\n",
              "  7,\n",
              "  3,\n",
              "  6,\n",
              "  9,\n",
              "  7,\n",
              "  4,\n",
              "  8,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  7,\n",
              "  8,\n",
              "  2,\n",
              "  5,\n",
              "  5,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  2,\n",
              "  4,\n",
              "  4,\n",
              "  9,\n",
              "  7,\n",
              "  7,\n",
              "  2,\n",
              "  8,\n",
              "  6,\n",
              "  3,\n",
              "  1,\n",
              "  3,\n",
              "  5,\n",
              "  6,\n",
              "  4,\n",
              "  0,\n",
              "  4,\n",
              "  6,\n",
              "  6,\n",
              "  2,\n",
              "  7,\n",
              "  8,\n",
              "  5,\n",
              "  5,\n",
              "  3,\n",
              "  6,\n",
              "  1,\n",
              "  4,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  4,\n",
              "  3,\n",
              "  5,\n",
              "  8,\n",
              "  7,\n",
              "  1,\n",
              "  7,\n",
              "  3,\n",
              "  5,\n",
              "  4,\n",
              "  2,\n",
              "  9,\n",
              "  8,\n",
              "  8,\n",
              "  0,\n",
              "  3,\n",
              "  8,\n",
              "  4,\n",
              "  6,\n",
              "  8,\n",
              "  9,\n",
              "  6,\n",
              "  2,\n",
              "  4,\n",
              "  1,\n",
              "  8,\n",
              "  7,\n",
              "  6,\n",
              "  3,\n",
              "  3,\n",
              "  1,\n",
              "  7,\n",
              "  0,\n",
              "  1,\n",
              "  3,\n",
              "  5,\n",
              "  1,\n",
              "  2,\n",
              "  3,\n",
              "  9,\n",
              "  6,\n",
              "  5,\n",
              "  4,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  4,\n",
              "  7,\n",
              "  2,\n",
              "  8,\n",
              "  4,\n",
              "  7,\n",
              "  8,\n",
              "  3,\n",
              "  3,\n",
              "  5,\n",
              "  1,\n",
              "  1,\n",
              "  7,\n",
              "  1,\n",
              "  1,\n",
              "  8,\n",
              "  8,\n",
              "  2,\n",
              "  4,\n",
              "  2,\n",
              "  7,\n",
              "  0,\n",
              "  6,\n",
              "  9,\n",
              "  6,\n",
              "  7,\n",
              "  3,\n",
              "  ...],\n",
              " [5,\n",
              "  7,\n",
              "  5,\n",
              "  5,\n",
              "  9,\n",
              "  1,\n",
              "  5,\n",
              "  4,\n",
              "  3,\n",
              "  3,\n",
              "  1,\n",
              "  6,\n",
              "  9,\n",
              "  3,\n",
              "  7,\n",
              "  2,\n",
              "  5,\n",
              "  8,\n",
              "  3,\n",
              "  1,\n",
              "  6,\n",
              "  6,\n",
              "  7,\n",
              "  3,\n",
              "  0,\n",
              "  6,\n",
              "  5,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  9,\n",
              "  5,\n",
              "  5,\n",
              "  3,\n",
              "  2,\n",
              "  4,\n",
              "  0,\n",
              "  3,\n",
              "  1,\n",
              "  7,\n",
              "  5,\n",
              "  7,\n",
              "  3,\n",
              "  5,\n",
              "  1,\n",
              "  6,\n",
              "  2,\n",
              "  6,\n",
              "  4,\n",
              "  8,\n",
              "  4,\n",
              "  8,\n",
              "  9,\n",
              "  2,\n",
              "  3,\n",
              "  8,\n",
              "  4,\n",
              "  4,\n",
              "  9,\n",
              "  1,\n",
              "  0,\n",
              "  6,\n",
              "  0,\n",
              "  7,\n",
              "  3,\n",
              "  5,\n",
              "  9,\n",
              "  8,\n",
              "  5,\n",
              "  7,\n",
              "  1,\n",
              "  4,\n",
              "  4,\n",
              "  1,\n",
              "  0,\n",
              "  9,\n",
              "  9,\n",
              "  3,\n",
              "  9,\n",
              "  1,\n",
              "  5,\n",
              "  4,\n",
              "  6,\n",
              "  1,\n",
              "  7,\n",
              "  6,\n",
              "  8,\n",
              "  6,\n",
              "  8,\n",
              "  1,\n",
              "  0,\n",
              "  5,\n",
              "  6,\n",
              "  0,\n",
              "  8,\n",
              "  0,\n",
              "  3,\n",
              "  9,\n",
              "  1,\n",
              "  6,\n",
              "  1,\n",
              "  1,\n",
              "  5,\n",
              "  0,\n",
              "  5,\n",
              "  9,\n",
              "  8,\n",
              "  4,\n",
              "  4,\n",
              "  0,\n",
              "  6,\n",
              "  0,\n",
              "  8,\n",
              "  5,\n",
              "  3,\n",
              "  8,\n",
              "  5,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  8,\n",
              "  2,\n",
              "  4,\n",
              "  7,\n",
              "  0,\n",
              "  0,\n",
              "  7,\n",
              "  1,\n",
              "  7,\n",
              "  8,\n",
              "  5,\n",
              "  2,\n",
              "  6,\n",
              "  2,\n",
              "  1,\n",
              "  7,\n",
              "  9,\n",
              "  9,\n",
              "  3,\n",
              "  5,\n",
              "  9,\n",
              "  0,\n",
              "  7,\n",
              "  6,\n",
              "  0,\n",
              "  8,\n",
              "  6,\n",
              "  2,\n",
              "  6,\n",
              "  9,\n",
              "  2,\n",
              "  7,\n",
              "  2,\n",
              "  1,\n",
              "  4,\n",
              "  8,\n",
              "  7,\n",
              "  2,\n",
              "  4,\n",
              "  3,\n",
              "  7,\n",
              "  0,\n",
              "  9,\n",
              "  9,\n",
              "  5,\n",
              "  4,\n",
              "  7,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  8,\n",
              "  6,\n",
              "  4,\n",
              "  6,\n",
              "  3,\n",
              "  4,\n",
              "  6,\n",
              "  3,\n",
              "  6,\n",
              "  8,\n",
              "  8,\n",
              "  2,\n",
              "  2,\n",
              "  9,\n",
              "  4,\n",
              "  9,\n",
              "  5,\n",
              "  1,\n",
              "  5,\n",
              "  8,\n",
              "  7,\n",
              "  2,\n",
              "  9,\n",
              "  3,\n",
              "  5,\n",
              "  8,\n",
              "  6,\n",
              "  5,\n",
              "  5,\n",
              "  9,\n",
              "  7,\n",
              "  5,\n",
              "  8,\n",
              "  4,\n",
              "  6,\n",
              "  4,\n",
              "  3,\n",
              "  0,\n",
              "  8,\n",
              "  3,\n",
              "  4,\n",
              "  8,\n",
              "  0,\n",
              "  4,\n",
              "  9,\n",
              "  4,\n",
              "  7,\n",
              "  2,\n",
              "  0,\n",
              "  5,\n",
              "  9,\n",
              "  5,\n",
              "  5,\n",
              "  3,\n",
              "  5,\n",
              "  0,\n",
              "  6,\n",
              "  0,\n",
              "  8,\n",
              "  6,\n",
              "  2,\n",
              "  5,\n",
              "  2,\n",
              "  1,\n",
              "  1,\n",
              "  9,\n",
              "  8,\n",
              "  7,\n",
              "  6,\n",
              "  5,\n",
              "  1,\n",
              "  4,\n",
              "  8,\n",
              "  5,\n",
              "  1,\n",
              "  4,\n",
              "  0,\n",
              "  2,\n",
              "  6,\n",
              "  5,\n",
              "  7,\n",
              "  8,\n",
              "  0,\n",
              "  3,\n",
              "  6,\n",
              "  1,\n",
              "  7,\n",
              "  6,\n",
              "  9,\n",
              "  0,\n",
              "  6,\n",
              "  1,\n",
              "  4,\n",
              "  8,\n",
              "  5,\n",
              "  2,\n",
              "  4,\n",
              "  9,\n",
              "  8,\n",
              "  8,\n",
              "  6,\n",
              "  3,\n",
              "  8,\n",
              "  9,\n",
              "  9,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  9,\n",
              "  7,\n",
              "  7,\n",
              "  8,\n",
              "  3,\n",
              "  4,\n",
              "  9,\n",
              "  2,\n",
              "  1,\n",
              "  5,\n",
              "  9,\n",
              "  3,\n",
              "  9,\n",
              "  8,\n",
              "  3,\n",
              "  9,\n",
              "  3,\n",
              "  7,\n",
              "  9,\n",
              "  0,\n",
              "  4,\n",
              "  9,\n",
              "  8,\n",
              "  4,\n",
              "  1,\n",
              "  6,\n",
              "  5,\n",
              "  4,\n",
              "  6,\n",
              "  8,\n",
              "  3,\n",
              "  0,\n",
              "  8,\n",
              "  0,\n",
              "  9,\n",
              "  1,\n",
              "  2,\n",
              "  8,\n",
              "  2,\n",
              "  1,\n",
              "  3,\n",
              "  3,\n",
              "  8,\n",
              "  5,\n",
              "  4,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  9,\n",
              "  1,\n",
              "  0,\n",
              "  5,\n",
              "  6,\n",
              "  5,\n",
              "  0,\n",
              "  5,\n",
              "  8,\n",
              "  5,\n",
              "  6,\n",
              "  8,\n",
              "  6,\n",
              "  4,\n",
              "  4,\n",
              "  2,\n",
              "  4,\n",
              "  8,\n",
              "  8,\n",
              "  6,\n",
              "  4,\n",
              "  8,\n",
              "  2,\n",
              "  0,\n",
              "  1,\n",
              "  3,\n",
              "  3,\n",
              "  2,\n",
              "  0,\n",
              "  7,\n",
              "  2,\n",
              "  7,\n",
              "  4,\n",
              "  1,\n",
              "  1,\n",
              "  6,\n",
              "  5,\n",
              "  1,\n",
              "  7,\n",
              "  7,\n",
              "  4,\n",
              "  9,\n",
              "  3,\n",
              "  5,\n",
              "  1,\n",
              "  9,\n",
              "  0,\n",
              "  3,\n",
              "  8,\n",
              "  4,\n",
              "  0,\n",
              "  9,\n",
              "  7,\n",
              "  4,\n",
              "  7,\n",
              "  6,\n",
              "  1,\n",
              "  2,\n",
              "  6,\n",
              "  2,\n",
              "  5,\n",
              "  4,\n",
              "  1,\n",
              "  9,\n",
              "  3,\n",
              "  3,\n",
              "  2,\n",
              "  3,\n",
              "  8,\n",
              "  8,\n",
              "  8,\n",
              "  1,\n",
              "  9,\n",
              "  4,\n",
              "  1,\n",
              "  4,\n",
              "  4,\n",
              "  7,\n",
              "  3,\n",
              "  6,\n",
              "  8,\n",
              "  1,\n",
              "  1,\n",
              "  5,\n",
              "  3,\n",
              "  7,\n",
              "  9,\n",
              "  0,\n",
              "  7,\n",
              "  1,\n",
              "  1,\n",
              "  0,\n",
              "  6,\n",
              "  9,\n",
              "  5,\n",
              "  4,\n",
              "  4,\n",
              "  5,\n",
              "  1,\n",
              "  9,\n",
              "  5,\n",
              "  7,\n",
              "  8,\n",
              "  4,\n",
              "  1,\n",
              "  7,\n",
              "  8,\n",
              "  7,\n",
              "  3,\n",
              "  7,\n",
              "  8,\n",
              "  9,\n",
              "  2,\n",
              "  7,\n",
              "  2,\n",
              "  7,\n",
              "  2,\n",
              "  5,\n",
              "  4,\n",
              "  1,\n",
              "  7,\n",
              "  9,\n",
              "  0,\n",
              "  4,\n",
              "  2,\n",
              "  4,\n",
              "  2,\n",
              "  6,\n",
              "  0,\n",
              "  7,\n",
              "  3,\n",
              "  8,\n",
              "  8,\n",
              "  9,\n",
              "  0,\n",
              "  4,\n",
              "  0,\n",
              "  0,\n",
              "  6,\n",
              "  7,\n",
              "  1,\n",
              "  0,\n",
              "  7,\n",
              "  6,\n",
              "  7,\n",
              "  2,\n",
              "  5,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  4,\n",
              "  7,\n",
              "  7,\n",
              "  3,\n",
              "  0,\n",
              "  4,\n",
              "  1,\n",
              "  2,\n",
              "  3,\n",
              "  9,\n",
              "  6,\n",
              "  3,\n",
              "  7,\n",
              "  6,\n",
              "  3,\n",
              "  0,\n",
              "  4,\n",
              "  3,\n",
              "  7,\n",
              "  8,\n",
              "  2,\n",
              "  3,\n",
              "  3,\n",
              "  2,\n",
              "  9,\n",
              "  8,\n",
              "  7,\n",
              "  0,\n",
              "  9,\n",
              "  5,\n",
              "  9,\n",
              "  5,\n",
              "  3,\n",
              "  5,\n",
              "  6,\n",
              "  1,\n",
              "  3,\n",
              "  1,\n",
              "  2,\n",
              "  9,\n",
              "  6,\n",
              "  6,\n",
              "  7,\n",
              "  2,\n",
              "  7,\n",
              "  2,\n",
              "  5,\n",
              "  3,\n",
              "  1,\n",
              "  3,\n",
              "  4,\n",
              "  9,\n",
              "  5,\n",
              "  2,\n",
              "  2,\n",
              "  7,\n",
              "  9,\n",
              "  9,\n",
              "  4,\n",
              "  6,\n",
              "  7,\n",
              "  3,\n",
              "  4,\n",
              "  1,\n",
              "  7,\n",
              "  8,\n",
              "  1,\n",
              "  7,\n",
              "  2,\n",
              "  7,\n",
              "  0,\n",
              "  5,\n",
              "  9,\n",
              "  4,\n",
              "  4,\n",
              "  7,\n",
              "  7,\n",
              "  1,\n",
              "  5,\n",
              "  0,\n",
              "  4,\n",
              "  9,\n",
              "  7,\n",
              "  1,\n",
              "  4,\n",
              "  6,\n",
              "  4,\n",
              "  0,\n",
              "  0,\n",
              "  6,\n",
              "  8,\n",
              "  7,\n",
              "  9,\n",
              "  2,\n",
              "  5,\n",
              "  9,\n",
              "  0,\n",
              "  5,\n",
              "  7,\n",
              "  4,\n",
              "  7,\n",
              "  2,\n",
              "  1,\n",
              "  9,\n",
              "  6,\n",
              "  8,\n",
              "  2,\n",
              "  1,\n",
              "  4,\n",
              "  4,\n",
              "  2,\n",
              "  9,\n",
              "  0,\n",
              "  4,\n",
              "  4,\n",
              "  8,\n",
              "  8,\n",
              "  5,\n",
              "  8,\n",
              "  2,\n",
              "  3,\n",
              "  5,\n",
              "  0,\n",
              "  9,\n",
              "  9,\n",
              "  2,\n",
              "  0,\n",
              "  7,\n",
              "  8,\n",
              "  6,\n",
              "  1,\n",
              "  4,\n",
              "  6,\n",
              "  0,\n",
              "  7,\n",
              "  3,\n",
              "  0,\n",
              "  9,\n",
              "  9,\n",
              "  2,\n",
              "  5,\n",
              "  6,\n",
              "  3,\n",
              "  8,\n",
              "  8,\n",
              "  7,\n",
              "  7,\n",
              "  7,\n",
              "  4,\n",
              "  0,\n",
              "  5,\n",
              "  5,\n",
              "  1,\n",
              "  4,\n",
              "  2,\n",
              "  7,\n",
              "  0,\n",
              "  4,\n",
              "  3,\n",
              "  6,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  1,\n",
              "  2,\n",
              "  6,\n",
              "  6,\n",
              "  4,\n",
              "  5,\n",
              "  8,\n",
              "  9,\n",
              "  2,\n",
              "  8,\n",
              "  0,\n",
              "  8,\n",
              "  2,\n",
              "  2,\n",
              "  4,\n",
              "  3,\n",
              "  8,\n",
              "  0,\n",
              "  2,\n",
              "  4,\n",
              "  5,\n",
              "  3,\n",
              "  7,\n",
              "  2,\n",
              "  2,\n",
              "  1,\n",
              "  3,\n",
              "  8,\n",
              "  2,\n",
              "  9,\n",
              "  5,\n",
              "  8,\n",
              "  9,\n",
              "  4,\n",
              "  2,\n",
              "  8,\n",
              "  8,\n",
              "  6,\n",
              "  6,\n",
              "  8,\n",
              "  9,\n",
              "  5,\n",
              "  6,\n",
              "  8,\n",
              "  4,\n",
              "  1,\n",
              "  5,\n",
              "  8,\n",
              "  3,\n",
              "  1,\n",
              "  2,\n",
              "  9,\n",
              "  6,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  7,\n",
              "  5,\n",
              "  5,\n",
              "  1,\n",
              "  2,\n",
              "  7,\n",
              "  8,\n",
              "  0,\n",
              "  2,\n",
              "  8,\n",
              "  0,\n",
              "  7,\n",
              "  0,\n",
              "  3,\n",
              "  8,\n",
              "  6,\n",
              "  9,\n",
              "  1,\n",
              "  4,\n",
              "  2,\n",
              "  4,\n",
              "  6,\n",
              "  2,\n",
              "  5,\n",
              "  1,\n",
              "  7,\n",
              "  1,\n",
              "  7,\n",
              "  0,\n",
              "  9,\n",
              "  7,\n",
              "  4,\n",
              "  5,\n",
              "  3,\n",
              "  0,\n",
              "  8,\n",
              "  5,\n",
              "  9,\n",
              "  4,\n",
              "  9,\n",
              "  3,\n",
              "  8,\n",
              "  4,\n",
              "  0,\n",
              "  1,\n",
              "  7,\n",
              "  3,\n",
              "  9,\n",
              "  2,\n",
              "  6,\n",
              "  0,\n",
              "  4,\n",
              "  9,\n",
              "  4,\n",
              "  5,\n",
              "  7,\n",
              "  8,\n",
              "  3,\n",
              "  2,\n",
              "  7,\n",
              "  3,\n",
              "  7,\n",
              "  2,\n",
              "  9,\n",
              "  8,\n",
              "  7,\n",
              "  4,\n",
              "  6,\n",
              "  8,\n",
              "  8,\n",
              "  3,\n",
              "  4,\n",
              "  0,\n",
              "  2,\n",
              "  1,\n",
              "  7,\n",
              "  1,\n",
              "  4,\n",
              "  3,\n",
              "  8,\n",
              "  2,\n",
              "  1,\n",
              "  3,\n",
              "  8,\n",
              "  6,\n",
              "  3,\n",
              "  2,\n",
              "  4,\n",
              "  7,\n",
              "  7,\n",
              "  4,\n",
              "  2,\n",
              "  8,\n",
              "  6,\n",
              "  6,\n",
              "  5,\n",
              "  9,\n",
              "  2,\n",
              "  6,\n",
              "  7,\n",
              "  9,\n",
              "  0,\n",
              "  4,\n",
              "  0,\n",
              "  4,\n",
              "  9,\n",
              "  1,\n",
              "  6,\n",
              "  8,\n",
              "  2,\n",
              "  6,\n",
              "  4,\n",
              "  0,\n",
              "  1,\n",
              "  7,\n",
              "  8,\n",
              "  5,\n",
              "  5,\n",
              "  1,\n",
              "  8,\n",
              "  9,\n",
              "  1,\n",
              "  7,\n",
              "  4,\n",
              "  6,\n",
              "  1,\n",
              "  3,\n",
              "  6,\n",
              "  5,\n",
              "  6,\n",
              "  1,\n",
              "  5,\n",
              "  8,\n",
              "  3,\n",
              "  2,\n",
              "  7,\n",
              "  0,\n",
              "  1,\n",
              "  3,\n",
              "  2,\n",
              "  9,\n",
              "  2,\n",
              "  5,\n",
              "  4,\n",
              "  2,\n",
              "  0,\n",
              "  3,\n",
              "  3,\n",
              "  4,\n",
              "  1,\n",
              "  8,\n",
              "  6,\n",
              "  7,\n",
              "  0,\n",
              "  0,\n",
              "  4,\n",
              "  4,\n",
              "  6,\n",
              "  3,\n",
              "  1,\n",
              "  3,\n",
              "  9,\n",
              "  4,\n",
              "  5,\n",
              "  3,\n",
              "  3,\n",
              "  7,\n",
              "  1,\n",
              "  5,\n",
              "  9,\n",
              "  3,\n",
              "  9,\n",
              "  3,\n",
              "  6,\n",
              "  7,\n",
              "  3,\n",
              "  6,\n",
              "  9,\n",
              "  7,\n",
              "  4,\n",
              "  8,\n",
              "  2,\n",
              "  1,\n",
              "  0,\n",
              "  9,\n",
              "  0,\n",
              "  2,\n",
              "  5,\n",
              "  9,\n",
              "  6,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  4,\n",
              "  4,\n",
              "  4,\n",
              "  9,\n",
              "  7,\n",
              "  7,\n",
              "  2,\n",
              "  8,\n",
              "  6,\n",
              "  3,\n",
              "  1,\n",
              "  3,\n",
              "  5,\n",
              "  0,\n",
              "  4,\n",
              "  0,\n",
              "  4,\n",
              "  4,\n",
              "  6,\n",
              "  2,\n",
              "  7,\n",
              "  8,\n",
              "  5,\n",
              "  5,\n",
              "  3,\n",
              "  6,\n",
              "  1,\n",
              "  4,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  4,\n",
              "  3,\n",
              "  5,\n",
              "  8,\n",
              "  7,\n",
              "  1,\n",
              "  7,\n",
              "  3,\n",
              "  5,\n",
              "  4,\n",
              "  2,\n",
              "  9,\n",
              "  8,\n",
              "  8,\n",
              "  0,\n",
              "  3,\n",
              "  8,\n",
              "  4,\n",
              "  6,\n",
              "  8,\n",
              "  9,\n",
              "  6,\n",
              "  2,\n",
              "  4,\n",
              "  1,\n",
              "  8,\n",
              "  7,\n",
              "  6,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  7,\n",
              "  0,\n",
              "  1,\n",
              "  3,\n",
              "  5,\n",
              "  1,\n",
              "  2,\n",
              "  3,\n",
              "  9,\n",
              "  0,\n",
              "  5,\n",
              "  2,\n",
              "  3,\n",
              "  3,\n",
              "  3,\n",
              "  4,\n",
              "  7,\n",
              "  2,\n",
              "  0,\n",
              "  4,\n",
              "  7,\n",
              "  8,\n",
              "  3,\n",
              "  3,\n",
              "  5,\n",
              "  1,\n",
              "  1,\n",
              "  7,\n",
              "  1,\n",
              "  1,\n",
              "  8,\n",
              "  8,\n",
              "  2,\n",
              "  4,\n",
              "  2,\n",
              "  7,\n",
              "  0,\n",
              "  0,\n",
              "  9,\n",
              "  6,\n",
              "  7,\n",
              "  3,\n",
              "  ...])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Var1()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 15\n",
        "losses_train = []\n",
        "losses_test = []\n",
        "\n",
        "train_test_loop(model, criterion, optimizer, epochs)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPl8TpaC799+YwP0pwwQXva",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
